<!doctype html><html lang=en-us><head><meta charset=utf-8><title>NixOS NAS | Josh Kasuboski</title><meta name=description content="Josh Kasuboski's personal site"><meta name=author content="Josh Kasuboski"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://www.joshkasuboski.com/img/josh-scotland-full.jpg"><meta name=twitter:title content="NixOS NAS"><meta name=twitter:description content="I've given in to hoarding and got 20TB of storage ðŸ«¢."><meta property="og:title" content="NixOS NAS"><meta property="og:description" content="I've given in to hoarding and got 20TB of storage ðŸ«¢."><meta property="og:type" content="article"><meta property="og:url" content="https://www.joshkasuboski.com/posts/nixos-nas/"><meta property="og:image" content="https://www.joshkasuboski.com/img/josh-scotland-full.jpg"><meta property="article:published_time" content="2023-09-19T12:46:18-05:00"><meta property="article:modified_time" content="2023-09-19T12:46:18-05:00"><link rel=me href=mailto:josh.kasuboski@gmail.com><link rel=me href=https://github.com/kasuboski><link data-proofer-ignore rel=authorization_endpoint href=https://indieauth.com/auth><link rel=token_endpoint href=https://tokens.indieauth.com/token><link data-proofer-ignore rel=microsub href=https://microsub.joshcorp.co/microsub><link rel=alternate type=application/rss+xml href=https://www.joshkasuboski.com/index.xml><meta name=viewport content="width=device-width,initial-scale=1"><link rel=stylesheet href=https://unpkg.com/turretcss/dist/turretcss.min.css crossorigin=anonymous><style>@media only screen and (min-width:768px){:root{font-size:18px}}body{background-color:#faf9fa}pre{background-color:#d4f2e1}a{text-decoration-color:#5965f9}#site-header{box-shadow:0 4px 12px 0 rgba(0,0,0,.05)}#intro{background-color:#e6e8fe}#social a{color:transparent;text-decoration:none}</style></head><body><div class=padding-bottom-s><header id=site-header><div class="container max-width-l flex-justify-center padding-vertical-xs"><h1 class=no-margin-bottom><a class="text-decoration-none flex align-items-center" href=https://www.joshkasuboski.com/><img alt="jk logo" class="icon-s margin-right-xs" src=https://www.joshkasuboski.com/images/jk-logo.svg><small>Josh Kasuboski</small></a></h1><nav class=nav-inline><ul><li><a href=/about/>About</a></li><li><a href=/now/>Now</a></li></ul></nav></div></header><main class="container max-width-l margin-top-l"><article class=h-entry><header><h1 class="display-title-xl no-margin-bottom post-title p-name">NixOS NAS</h1><p class="post-date no-margin-top">Posted on
<time class=dt-published datetime=2023-09-19T12:46:18-05:00>19 September, 2023</time> by <a href=https://www.joshkasuboski.com/ class="p-author h-card" rel=author>Josh Kasuboski</a> Â· 5min read</p></header><section class="content e-content margin-top-l"><p>I've given in to hoarding and got 20TB of storage ðŸ«¢.</p><h2 id=previous-setup>Previous Setup</h2><p>I had been using an external USB hard drive as my storage. It's attached to one of my kubernetes nodes which also runs NFS so other nodes can reach the storage. There's actually a very similar setup in Wisconsin which acted as a backup.</p><p>This worked pretty well, but I'd have issues with clients disconnecting randomly and rather slow access speeds. I assume this was largely from the combo of NFS and a USB drive, but didn't investigate too much. The hard drive was fairly large at 16TB, but I didn't use it much because of the above issues.</p><p>Moving forward I wanted to get more storage that can be accessed reliably as well as have the possibility to grow.</p><h2 id=planning>Planning</h2><p>My old gaming PC was sitting unused in a rack mount chassis with hard drive bays. It seemed like the perfect fit for a new server dedicated to storage. There are pictures of the setup in my <a href=https://www.joshkasuboski.com/posts/server-rack-2/>post</a> about rack mounting the PC.</p><p>I was mainly going to be storing media files and anything important would have multiple copies stored elsewhere. I'm also much too lazy to deal with some of the restrictions that come with a ZFS pool about managing vdevs and drive sizes. I decided on using a <a href=https://github.com/trapexit/mergerfs>mergerfs</a> pool.</p><p>Mergerfs allows you to combine multiple drives under a single mountpoint. Depending on your configuration you can have the files distributed across them as well. So if a drive dies you're only out the files that were on that drive (not everything). Since most of my files won't change that often, I can also use <a href=https://www.snapraid.it/>SnapRaid</a>. It stores parity data of your files so that you can recover from drive failure. SnapRaid isn't as robust as something like ZFS since it works on snapshots, meaning there is a period of time where your new files aren't covered.</p><p>SnapRaid uses a parity drive that must be at least as big as your biggest data drive. I decided to go with two 12TB data drives and an 18TB parity drive. This would give me an increase in storage capacity and allow me to go up to an 18TB data drive in the future.</p><p>Part of my problem with the previous solution was that I had to remember how to setup NFS and mount the disk correctly every time. I wanted to make sure that not only was it documented, but there wouldn't be hidden changes I forget about.</p><p>I decided to take the plunge to an ephemeral NixOS since I had been liking <a href=https://www.joshkasuboski.com/posts/nix-dev-environment/>nix for development environments</a>.</p><h2 id=setting-it-up>Setting it up</h2><p>Installing NixOS was a little different since I wanted an ephemeral root. This meant everytime the PC restarts the root partition would be erased. This is actually implemented by rolling back to an empty btrfs snapshot, but the effect is the same. Anything that isn't explicitly set to persist will be erased.</p><p>There are a few things that are always persisted. The nix store stays around so it doesn't rebuild the world everytime. There is also a <code>/persist</code> mount that stays for anything like application state that should stick around. I also currently have a persistent <code>home</code>, but it's not really necessary.</p><p>I have a pretty rough guide at <a href=https://github.com/kasuboski/home-infra/blob/0fb543fc9a0d5065cc0b1e31b0d2c2742cc62c1a/nas.md>kasboski/home-infra/nas.md</a>. I generally followed <a href=https://guekka.github.io/nixos-server-1/>https://guekka.github.io/nixos-server-1/</a> with some tweaks for my case.</p><p>My server was then setup to be entirely controlled by the nix config. You can skip to just reading the <code>nix</code> at <a href=https://github.com/kasuboski/dotfiles/blob/a5bb2bc2b819edea75a08afac350a042f5a533f4/nixos/hosts/fettig/configuration.nix>kasuboski/dotfiles</a>. I'm not sure my dotfiles repo is really the place for this, but I didn't have a better idea.</p><p>I was much more confident in editing the server now that I could always revert to a known working config.</p><p>Adding the storage disks, I mostly went with the instructions from <a href=https://wiki.selfhosted.show/tools/snapraid-btrfs/>SnapRaid-Btrfs</a>. It formats the data drives with <code>btrfs</code> which helps alleviate the issue for snapraid where it needs to snapshot while files are available, but not changing. Snapraid btrfs orchestrates taking a readonly btrfs snapshot and then runs snapraid on the snapshot.</p><p>Snapraid btrfs and the runner mentioned weren't already packaged with nix, which led me to learning more about packaging random projects for nix. It took me quite awhile as the combo wasn't really meant to run without system dependencies. I had issues where it would work under my user which had local dependencies, but then it would fail in an isolated systemd service.</p><p>The entire setup when configured manually requires quite a few steps. My resulting configuration is by no means simple, but I think it at least points me in the right direction of how things are setup. The main file is <a href=https://github.com/kasuboski/dotfiles/blob/a5bb2bc2b819edea75a08afac350a042f5a533f4/nixos/hosts/fettig/storage.nix>storage.nix</a> that lists the drives, maps them as data or parity and mounts them, while setting up the snapraid config.</p><p>Getting NFS and Samba shares setup was also somewhat straight forward considering I had followed random guides how to do it before. It's nice to be able to configure a user for the share, a mount point, and the system services all in the same place. I still had to spend quite a bit of time investigating the specific NFS and Samba options I wanted, but I didn't need to hunt down where to add them or how to make it take effect.</p><h2 id=moving-forward>Moving Forward</h2><p>I'm pretty happy with the setup. Adding services with nix is often as simple as enabling them. I want to setup an actual replication solution since currently I just run rsync to my old external hard drive every now and then. I also want to host various services that take advantage of the storage now. Some examples might be hosting photos or a personal pastebin.</p><p>I had started to use the NAS as a dev server since it was nice to have a powerful machine that could use a nix dev environment. I now kind of want to get a dedicated development machine to connect to instead of messing with that machine. Maybe a <a href=https://nixos.wiki/wiki/NixOS_Containers>NixOS Container</a> would be isolated enough instead.</p><p>I also can't resist trying to run a kubernetes node on it. I am thinking I'd want it to be in a VM or see if a NixOS container would work though. Preferably the storage aspects wouldn't really need to know about the k8s node.</p></section><footer class=margin-top-m><a class="permalink u-url text-decoration-none" href=https://www.joshkasuboski.com/posts/nixos-nas/>ðŸ”—</a></footer></article><nav class="margin-top-l flex justify-content-space-around"><div></div><div class=show-s-up><a data-proofer-ignore alt="Top of page" href=#>Top</a></div><div><a alt="Older article" href=https://www.joshkasuboski.com/posts/nix-dev-environment/>NixOS Dev Environment on Mac &rarr;</a></div></nav></main><footer class="container max-width-l margin-top-xl"><div class=margin-bottom-m><h4>Get more of my thoughts in an email newsletter!</h4><form action=https://buttondown.email/api/emails/embed-subscribe/kasuboski method=post target=popupwindow onsubmit="window.open('https://buttondown.email/kasuboski','popupwindow')" class=embeddable-buttondown-form><label for=bd-email>Your Email</label>
<input type=email name=email id=bd-email placeholder=me@email.com></input>
<input type=hidden value=1 name=embed></input>
<button class="button button-primary button-border" type=submit value=Subscribe>Subscribe</button><p class=font-size-s><a href=https://buttondown.email target=_blank>Powered by Buttondown.</a></p></form></div><div class="box-shadow-l padding-m"><div class="h-card flex align-content-center"><figure class=icon-xxl><img alt="profile photo" class=u-photo src=https://www.joshkasuboski.com/img/josh-scotland.jpg></figure><div class=margin-left-m><h3 class=display-title><a class="u-url p-name text-decoration-none" href=https://www.joshkasuboski.com/>Josh Kasuboski</a></h3><p>Living in Austin <img class=icon-xs style=vertical-align:middle alt=texas src=https://www.joshkasuboski.com/img/tx-fill.png> from <img class=icon-xs style=vertical-align:middle alt=wisconsin src=https://www.joshkasuboski.com/img/wi-fill.png></p><p id=social><a rel=me class="u-url margin-right-xs" href=https://github.com/kasuboski><img class=icon-xs src=https://www.joshkasuboski.com/icons/github.svg alt=github></a>
<a class=margin-right-xs href=https://linkedin.com/in/joshkasuboski/><img class=icon-xs src=https://www.joshkasuboski.com/icons/linkedin.svg alt=linkedin></a>
<a href=mailto:josh.kasuboski@gmail.com class="u-email margin-right-xxs" rel=me><img class=icon-xs src=https://www.joshkasuboski.com/icons/envelope.svg alt=email></a>
<a href=https://www.joshkasuboski.com/payments/><img class=icon-xs src=https://www.joshkasuboski.com/icons/beer-money-icon.svg alt=beermoney></a></p></div></div></div></footer></div><script async src=https://rum.cronitor.io/script.js></script><script>window.cronitor=window.cronitor||function(){(window.cronitor.q=window.cronitor.q||[]).push(arguments);};cronitor('config',{clientKey:'b2a9cb0f440d559169438f89c882dddb'});</script></body></html>